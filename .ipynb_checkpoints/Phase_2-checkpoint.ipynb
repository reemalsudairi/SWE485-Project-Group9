{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba7a1f8-36f5-468d-a7e1-75bb8ac49835",
   "metadata": {},
   "source": [
    "## Performance Evaluation Metrics  \n",
    "\n",
    "To assess the effectiveness of our models, we need to use appropriate performance measures. In this case, we have chosen accuracy score and classification report as our primary evaluation metrics.  \n",
    "\n",
    "## Why These Metrics?\n",
    "\n",
    "### Accuracy Score\n",
    "- Accuracy provides a straightforward measure of overall model performance by calculating the proportion of correct predictions out of all predictions.  \n",
    "- Since we are dealing with a binary classification problem, accuracy serves as a useful baseline metric to compare the models.  \n",
    "- This metric is particularly relevant when class distribution is not highly imbalanced, allowing us to assess how well the models differentiate between similar and non-similar properties.\n",
    " \n",
    "It is defined as:  \n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}\n",
    "$$\n",
    "\n",
    "\n",
    "### Classification Report\n",
    "While accuracy gives a general performance overview, it does not reveal how well the model handles each class. The classification report provides a more detailed evaluation through:  \n",
    "\n",
    "- Precision â€“ Measures how many of the predicted similar properties were actually similar, helping assess false positives. It is defined as:  \n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\n",
    "$$\n",
    "\n",
    "A high precision score indicates that the model makes few false positive predictions.  \n",
    "\n",
    "- Recall â€“ Measures how well the model identifies all similar properties, ensuring we minimize false negatives. It is defined as:  \n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n",
    "$$\n",
    "\n",
    "A high recall score means the model is good at identifying positive instances.  \n",
    "\n",
    "- F1-Score â€“ Balances precision and recall, making it useful if there are slight class imbalances. It is defined as:  \n",
    "\n",
    "$$\n",
    "F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "A high F1-score indicates a good balance between precision and recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "54f121bd-17a6-4686-981b-07d1a91cc26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      " KNN Performance Metrics:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Accuracy: 0.9026\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.77      0.69        22\n",
      "           1       0.96      0.92      0.94       132\n",
      "\n",
      "    accuracy                           0.90       154\n",
      "   macro avg       0.80      0.85      0.82       154\n",
      "weighted avg       0.91      0.90      0.91       154\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Random Forest Performance Metrics:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Accuracy: 0.9545\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85        22\n",
      "           1       0.98      0.96      0.97       132\n",
      "\n",
      "    accuracy                           0.95       154\n",
      "   macro avg       0.89      0.94      0.91       154\n",
      "weighted avg       0.96      0.95      0.96       154\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Gradient Boosting Performance Metrics:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Accuracy: 0.9286\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.76        22\n",
      "           1       0.96      0.95      0.96       132\n",
      "\n",
      "    accuracy                           0.93       154\n",
      "   macro avg       0.85      0.86      0.86       154\n",
      "weighted avg       0.93      0.93      0.93       154\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© ÙˆØ§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ¯Ù„ KNN:\n",
      "\n",
      "Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø§Ø± | Ø§Ù„Ù…ÙˆÙ‚Ø¹ | Ø§Ù„Ø­ÙŠ | Ø§Ù„ØºØ±Ù | Ø¯ÙˆØ±Ø§Øª Ø§Ù„Ù…ÙŠØ§Ø© | Ø§Ù„Ù…Ø³Ø§Ø­Ø© | Ø§Ù„Ø³Ø¹Ø± | Ø§Ù„ÙˆÙƒØ§Ù„Ø©\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ÙÛŒÙ„Ø§ | Ø¬Ù†ÙˆØ¨ | Ø¨Ø¯Ø± | 6 | 6 | 300 | 980000 | Ù…Ø¤Ø³Ø³Ø© ØºØ²Ø§Ù„Ø© Ù„Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠØ©\n",
      "Ø´Ù‚Ø© | Ø´Ø±Ù‚ | Ø§Ù„Ø±Ù…Ø§Ù„ | 5 | 4 | 175 | 1000000 | Ø¥Ø³ÙƒØ§Ù† Ø³Ù„Ù…Ø§Ù† Ù„Ù„ØªØ³ÙˆÙŠÙ‚ Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠ\n",
      "Ø¯ÙˆØ± | ØºØ±Ø¨ | Ø·ÙˆÙŠÙ‚ | 5 | 4 | 172 | 800000 | Ø¥Ø³ÙƒØ§Ù† Ø³Ù„Ù…Ø§Ù† Ù„Ù„ØªØ³ÙˆÙŠÙ‚ Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠ\n",
      "ÙÛŒÙ„Ø§ | Ø¬Ù†ÙˆØ¨ | Ø§Ù„Ø¯Ø§Ø± Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡ | 7 | 5 | 367 | 1000000 | Ù…ÙƒØªØ¨ Ø§Ù„Ø§Ø­Ù…Ø¯ÙŠ Ù„Ù„Ø¹Ù‚Ø§Ø±Ø§Øª\n",
      "Ø´Ù‚Ø© | Ø¬Ù†ÙˆØ¨ | Ø¨Ø¯Ø± | 3 | 3 | 169 | 450000 | Ø´Ø±ÙƒØ© Ù†Ø¬Ù…Ø© Ø§Ù„ØªÙ…ÙŠØ² Ù„Ù„Ø¹Ù‚Ø§Ø±Ø§Øª\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© ÙˆØ§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ¯Ù„ Random Forest:\n",
      "\n",
      "Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø§Ø± | Ø§Ù„Ù…ÙˆÙ‚Ø¹ | Ø§Ù„Ø­ÙŠ | Ø§Ù„ØºØ±Ù | Ø¯ÙˆØ±Ø§Øª Ø§Ù„Ù…ÙŠØ§Ø© | Ø§Ù„Ù…Ø³Ø§Ø­Ø© | Ø§Ù„Ø³Ø¹Ø± | Ø§Ù„ÙˆÙƒØ§Ù„Ø©\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ÙÛŒÙ„Ø§ | Ø¬Ù†ÙˆØ¨ | Ø¨Ø¯Ø± | 6 | 6 | 300 | 980000 | Ù…Ø¤Ø³Ø³Ø© ØºØ²Ø§Ù„Ø© Ù„Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠØ©\n",
      "Ø¯ÙˆØ± | Ø´Ø±Ù‚ | Ø§Ù„Ø¨ÙŠØ§Ù† | 4 | 4 | 172 | 1050000 | Ø¥Ø³ÙƒØ§Ù† Ø³Ù„Ù…Ø§Ù† Ù„Ù„ØªØ³ÙˆÙŠÙ‚ Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠ\n",
      "ÙÛŒÙ„Ø§ | ØºØ±Ø¨ | Ø§Ù„Ù…Ù‡Ø¯ÙŠØ© | 6 | 6 | 400 | 2300000 | Ø¥Ø³ÙƒØ§Ù† Ø³Ù„Ù…Ø§Ù† Ù„Ù„ØªØ³ÙˆÙŠÙ‚ Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠ\n",
      "Ø¯ÙˆØ± | Ø´Ø±Ù‚ | Ø§Ù„Ù…ÙˆÙ†Ø³ÙŠØ© | 6 | 5 | 185 | 1400000 | Ø³ÙƒÙ† Ø§Ù„Ù…Ø¹Ø§Ù„ÙŠ Ù„Ù„Ø¹Ù‚Ø§Ø±Ø§Øª\n",
      "Ø´Ù‚Ø© | Ø¬Ù†ÙˆØ¨ | Ø¨Ø¯Ø± | 4 | 4 | 227 | 680000 | Ø¥Ø³ÙƒØ§Ù† Ø³Ù„Ù…Ø§Ù† Ù„Ù„ØªØ³ÙˆÙŠÙ‚ Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠ\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© ÙˆØ§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ¯Ù„ Gradient Boosting:\n",
      "\n",
      "Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø§Ø± | Ø§Ù„Ù…ÙˆÙ‚Ø¹ | Ø§Ù„Ø­ÙŠ | Ø§Ù„ØºØ±Ù | Ø¯ÙˆØ±Ø§Øª Ø§Ù„Ù…ÙŠØ§Ø© | Ø§Ù„Ù…Ø³Ø§Ø­Ø© | Ø§Ù„Ø³Ø¹Ø± | Ø§Ù„ÙˆÙƒØ§Ù„Ø©\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ø¯ÙˆØ± | Ø´Ø±Ù‚ | Ø§Ù„Ù…ÙˆÙ†Ø³ÙŠØ© | 3 | 2 | 621 | 1500000 | Ù…Ø¤Ø³Ø³Ø© ÙˆØ³Ø§Ù… Ø§Ù„Ù…Ø³Ø§ÙƒÙ† Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠØ©\n",
      "ÙÛŒÙ„Ø§ | Ø¬Ù†ÙˆØ¨ | Ø§Ù„Ø¯Ø§Ø± Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡ | 11 | 11 | 750 | 2300000 | Ù…ÙƒØªØ¨ Ø§Ø³Ø§ØªØ°Ø© Ø§Ù„Ø¹Ù‚Ø§Ø± Ù„Ù„Ø¹Ù‚Ø§Ø±Ø§Øª\n",
      "ÙÛŒÙ„Ø§ | Ø´Ø±Ù‚ | Ø§Ù„ØµÙØ§ | 4 | 4 | 2480 | 2199000 | Ø´Ø±ÙƒØ© Ø±Ø§ÙƒØ² Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠØ©\n",
      "ÙÛŒÙ„Ø§ | ØºØ±Ø¨ | Ø·ÙˆÙŠÙ‚ | 8 | 5 | 796 | 2400000 | Ø´Ø±ÙƒØ© ØªØ±ÙƒÙŠ Ø§Ø¨Ø±Ø§Ù‡ÙŠÙ… Ø§Ù„Ù…Ø­ÙŠØ³Ù† Ù„Ù„Ø¹Ù‚Ø§Ø±Ø§Øª\n",
      "ÙÛŒÙ„Ø§ | Ø´Ø±Ù‚ | Ø§Ù„Ù†Ù‡Ø¶Ø© | 5 | 6 | 780 | 2964000 | Ù…Ø¤Ø³Ø³Ø© Ù†Ø¬Ù…Ø© Ø§Ù„Ø´Ø±Ù‚ Ù„Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠØ©\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"Dataset/cleaned_dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the \"Property_ID\" column as it's an identifier not useful for modeling.\n",
    "df = df.drop(columns=[\"Property_ID\"], errors='ignore')\n",
    "\n",
    "# Define the numerical features which we will use for analysis and predictions.\n",
    "num_features = [\"Area\", \"Price\"]\n",
    "\n",
    "# These columns will keep the original, unscaled values to display later in the recommendations.\n",
    "df[\"Original_Area\"] = df[\"Area\"]\n",
    "df[\"Original_Price\"] = df[\"Price\"]\n",
    "\n",
    "# A preprocessing pipeline is created using a StandardScaler to normalize the 'Area' and 'Price' columns for consistent scaling of the data.\n",
    "preprocessor = Pipeline([\n",
    "    ('scaler', StandardScaler())  # This scales the features to have zero mean and unit variance.\n",
    "])\n",
    "\n",
    "# Normalize the numerical features (Area and Price).\n",
    "df[num_features] = preprocessor.fit_transform(df[num_features])\n",
    "\n",
    "# Generate similarity labels for training. This function assigns a 'Similarity_Label' to properties based on their proximity to each other in price and area.\n",
    "df[\"Similarity_Label\"] = 0  # Default label is \"Not similar\".\n",
    "\n",
    "def assign_similarity_labels(df, threshold=0.1):\n",
    "    for i, row in df.iterrows():\n",
    "        area, price = row[\"Area\"], row[\"Price\"]\n",
    "        # Calculate the Euclidean distance between this property and all others.\n",
    "        distances = np.sqrt((df[\"Area\"] - area) ** 2 + (df[\"Price\"] - price) ** 2)\n",
    "        closest_indices = distances.nsmallest(3).index  # Adjusted to 2 closest + itself.\n",
    "        df.loc[closest_indices, \"Similarity_Label\"] = 1  # Mark these properties as similar.\n",
    "\n",
    "assign_similarity_labels(df)\n",
    "\n",
    "# We will split the data into a training set (80%) and a testing set (20%) for model evaluation.\n",
    "X = df[num_features]\n",
    "y = df[\"Similarity_Label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# We will train three models: KNN, Random Forest, and Gradient Boosting.\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5, weights=\"distance\"),  # Enable probability-based similarity\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100)\n",
    "}\n",
    "\n",
    "\n",
    "# Train each model and evaluate it using accuracy and classification report.\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Train the model on the training set.\n",
    "    y_pred = model.predict(X_test)  # Make predictions on the test set.\n",
    "    \n",
    "    # Output the accuracy score and classification report for each model with clear separation\n",
    "    print(f\"\\n{'-'*100}\")\n",
    "    print(f\" {name} Performance Metrics:\")\n",
    "    print(f\"{'-'*100}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"{'-'*100}\")\n",
    "\n",
    "# This function will return a list of recommended properties based on the price and area specified by the user.\n",
    "def recommend_properties(price, area, model_name, top_n=5):\n",
    "    input_data = pd.DataFrame([[area, price]], columns=num_features)\n",
    "    input_data_scaled = pd.DataFrame(preprocessor.transform(input_data), columns=num_features)\n",
    "\n",
    "    model = models.get(model_name)\n",
    "\n",
    "    if model is None:\n",
    "        print(f\"ğŸš¨ Model '{model_name}' not found!\")\n",
    "        return None\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):  \n",
    "        # **Use only the input property for prediction**\n",
    "        input_prob = model.predict_proba(input_data_scaled)[:, 1]\n",
    "\n",
    "        # **Predict probabilities for all properties compared to input**\n",
    "        probabilities = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    elif isinstance(model, KNeighborsClassifier):  \n",
    "        # **For KNN: Find closest properties to the input**\n",
    "        distances, indices = model.kneighbors(input_data_scaled, n_neighbors=min(top_n + 5, len(X)))  \n",
    "        probabilities = np.zeros(len(X))  \n",
    "        probabilities[indices.flatten()] = 1 / (distances.flatten() + 1e-5)  \n",
    "\n",
    "    else:\n",
    "        # **Fallback: Use Euclidean distance manually**\n",
    "        probabilities = -np.sqrt((df[\"Area\"] - input_data_scaled.iloc[0, 0]) ** 2 + (df[\"Price\"] - input_data_scaled.iloc[0, 1]) ** 2)\n",
    "\n",
    "    # **Sort based on highest similarity to input**\n",
    "    recommended_indices = np.argsort(-probabilities)[:top_n]\n",
    "    recommended = df.iloc[recommended_indices].copy()\n",
    "\n",
    "    # **Rename columns to Arabic**\n",
    "    recommended = recommended.rename(columns={\n",
    "        \"Property Type\": \"Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø§Ø±\",\n",
    "        \"Location\": \"Ø§Ù„Ù…ÙˆÙ‚Ø¹\",\n",
    "        \"District\": \"Ø§Ù„Ø­ÙŠ\",\n",
    "        \"Bedrooms\": \"Ø§Ù„ØºØ±Ù\",\n",
    "        \"Bathrooms\": \"Ø¯ÙˆØ±Ø§Øª Ø§Ù„Ù…ÙŠØ§Ø©\",\n",
    "        \"Original_Area\": \"Ø§Ù„Ù…Ø³Ø§Ø­Ø©\",\n",
    "        \"Original_Price\": \"Ø§Ù„Ø³Ø¹Ø±\",\n",
    "        \"Agency_Name\": \"Ø§Ù„ÙˆÙƒØ§Ù„Ø©\"\n",
    "    })\n",
    "\n",
    "    headers = [\"Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø§Ø±\", \"Ø§Ù„Ù…ÙˆÙ‚Ø¹\", \"Ø§Ù„Ø­ÙŠ\", \"Ø§Ù„ØºØ±Ù\", \"Ø¯ÙˆØ±Ø§Øª Ø§Ù„Ù…ÙŠØ§Ø©\", \"Ø§Ù„Ù…Ø³Ø§Ø­Ø©\", \"Ø§Ù„Ø³Ø¹Ø±\", \"Ø§Ù„ÙˆÙƒØ§Ù„Ø©\"]\n",
    "    results = recommended[headers]\n",
    "\n",
    "    print(f\"\\n ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© ÙˆØ§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ¯Ù„ {model_name}:\\n\")\n",
    "    print(\" | \".join(headers))\n",
    "    print(\"-\" * 100)\n",
    "    for _, row in results.iterrows():\n",
    "        print(\" | \".join(str(x) for x in row.values))\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage of the agar recommendation system:\n",
    "price_input = 1000\n",
    "area_input = 300\n",
    "\n",
    "# Loop through all models and print recommendations for each one.\n",
    "for model_name in models.keys():\n",
    "    recommend_properties(price_input, area_input, model_name=model_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
