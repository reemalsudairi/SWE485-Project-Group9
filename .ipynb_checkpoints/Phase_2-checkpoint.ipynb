{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54f121bd-17a6-4686-981b-07d1a91cc26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.9545\n",
      "KNN Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79        15\n",
      "           1       0.99      0.96      0.97       139\n",
      "\n",
      "    accuracy                           0.95       154\n",
      "   macro avg       0.85      0.92      0.88       154\n",
      "weighted avg       0.96      0.95      0.96       154\n",
      "\n",
      "Random Forest Accuracy: 0.9545\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79        15\n",
      "           1       0.99      0.96      0.97       139\n",
      "\n",
      "    accuracy                           0.95       154\n",
      "   macro avg       0.85      0.92      0.88       154\n",
      "weighted avg       0.96      0.95      0.96       154\n",
      "\n",
      "Gradient Boosting Accuracy: 0.9545\n",
      "Gradient Boosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79        15\n",
      "           1       0.99      0.96      0.97       139\n",
      "\n",
      "    accuracy                           0.95       154\n",
      "   macro avg       0.85      0.92      0.88       154\n",
      "weighted avg       0.96      0.95      0.96       154\n",
      "\n",
      "\n",
      "ğŸ”¹ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© ÙˆØ§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ¯Ù„ KNN:\n",
      "\n",
      "\n",
      "Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø§Ø± | Ø§Ù„Ù…ÙˆÙ‚Ø¹ | Ø§Ù„Ø­ÙŠ | Ø§Ù„ØºØ±Ù | Ø¯ÙˆØ±Ø§Øª Ø§Ù„Ù…ÙŠØ§Ø© | Ø§Ù„Ù…Ø³Ø§Ø­Ø© | Ø§Ù„Ø³Ø¹Ø± | Ø§Ù„ÙˆÙƒØ§Ù„Ø©\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "ÙÛŒÙ„Ø§ | Ø¬Ù†ÙˆØ¨ | Ø¨Ø¯Ø± | 6 | 6 | 300 | 980000 | Ù…Ø¤Ø³Ø³Ø© ØºØ²Ø§Ù„Ø© Ù„Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠØ©\n",
      "Ø¯ÙˆØ± | Ø´Ø±Ù‚ | Ø§Ù„Ø®Ù„ÙŠØ¬ | 6 | 5 | 500 | 1249000 | Ø´Ø±ÙƒØ© Ø³ÙŠØ§Ø¯ Ù„Ù„Ø§Ø³ØªØ«Ù…Ø§Ø±\n",
      "Ø¯ÙˆØ± | Ø´Ø±Ù‚ | Ø§Ù„Ø±ÙŠØ§Ù† | 5 | 4 | 523 | 1650000 | Ø´Ø±ÙƒØ© Ø³ÙŠØ§Ø¯ Ù„Ù„Ø§Ø³ØªØ«Ù…Ø§Ø±\n",
      "Ø¯ÙˆØ± | ÙˆØ³Ø· | Ø§Ù„Ø±Ø¨ÙˆØ© | 4 | 3 | 3098 | 1350000 | Ù…Ø³Ø§ÙƒÙ† Ø±ÙƒØ§Ø² Ù„Ù„Ø¹Ù‚Ø§Ø±Ø§Øª\n",
      "ÙÛŒÙ„Ø§ | Ø´Ø±Ù‚ | Ø§Ù„Ù…Ù„Ø² | 5 | 5 | 500 | 3500000 | Ù…Ø¤Ø³Ø³Ø© Ø³Ø¹ÙˆØ¯ Ø¹Ù„ÙŠ Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ² Ø§Ù„Ø³Ù‚Ø§Ù…ÙŠ Ù„Ù„Ø¹Ù‚Ø§Ø±Ø§Øª\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ”¹ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© ÙˆØ§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ¯Ù„ Random Forest:\n",
      "\n",
      "\n",
      "Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø§Ø± | Ø§Ù„Ù…ÙˆÙ‚Ø¹ | Ø§Ù„Ø­ÙŠ | Ø§Ù„ØºØ±Ù | Ø¯ÙˆØ±Ø§Øª Ø§Ù„Ù…ÙŠØ§Ø© | Ø§Ù„Ù…Ø³Ø§Ø­Ø© | Ø§Ù„Ø³Ø¹Ø± | Ø§Ù„ÙˆÙƒØ§Ù„Ø©\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "ÙÛŒÙ„Ø§ | Ø¬Ù†ÙˆØ¨ | Ø¨Ø¯Ø± | 6 | 6 | 300 | 980000 | Ù…Ø¤Ø³Ø³Ø© ØºØ²Ø§Ù„Ø© Ù„Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠØ©\n",
      "Ø¯ÙˆØ± | Ø´Ø±Ù‚ | Ø§Ù„Ø±ÙŠØ§Ù† | 5 | 4 | 523 | 1650000 | Ø´Ø±ÙƒØ© Ø³ÙŠØ§Ø¯ Ù„Ù„Ø§Ø³ØªØ«Ù…Ø§Ø±\n",
      "Ø¯ÙˆØ± | ÙˆØ³Ø· | Ø§Ù„Ø±Ø¨ÙˆØ© | 4 | 3 | 3098 | 1350000 | Ù…Ø³Ø§ÙƒÙ† Ø±ÙƒØ§Ø² Ù„Ù„Ø¹Ù‚Ø§Ø±Ø§Øª\n",
      "ÙÛŒÙ„Ø§ | Ø´Ø±Ù‚ | Ø§Ù„Ù…Ù„Ø² | 5 | 5 | 500 | 3500000 | Ù…Ø¤Ø³Ø³Ø© Ø³Ø¹ÙˆØ¯ Ø¹Ù„ÙŠ Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ² Ø§Ù„Ø³Ù‚Ø§Ù…ÙŠ Ù„Ù„Ø¹Ù‚Ø§Ø±Ø§Øª\n",
      "Ø¹Ù…Ø§Ø±Ø© | ØºØ±Ø¨ | Ø§Ù„Ø¬Ø±Ø§Ø¯ÙŠØ© | 11 | 11 | 1200 | 5500000 | Ø´Ø±ÙƒØ© Ø§Ù„ÙˆØ¯ÙŠØ§Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠÙ‡ Ù„Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠ\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ”¹ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© ÙˆØ§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ¯Ù„ Gradient Boosting:\n",
      "\n",
      "\n",
      "Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø§Ø± | Ø§Ù„Ù…ÙˆÙ‚Ø¹ | Ø§Ù„Ø­ÙŠ | Ø§Ù„ØºØ±Ù | Ø¯ÙˆØ±Ø§Øª Ø§Ù„Ù…ÙŠØ§Ø© | Ø§Ù„Ù…Ø³Ø§Ø­Ø© | Ø§Ù„Ø³Ø¹Ø± | Ø§Ù„ÙˆÙƒØ§Ù„Ø©\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Ø´Ù‚Ø© | Ø´Ù…Ø§Ù„ | Ø§Ù„Ø¹Ø§Ø±Ø¶ | 3 | 3 | 125 | 880000 | Ù…ÙƒØªØ¨ Ø¨Ø¯Ø± Ø­Ù…Ø¯ Ø§Ù„Ù…ÙˆØ³Ù‰ Ù„Ù„Ø¹Ù‚Ø§Ø±Ø§Øª\n",
      "Ø´Ù‚Ø© | Ø´Ù…Ø§Ù„ | Ø§Ù„Ù…Ù„Ù‚Ø§ | 3 | 3 | 126 | 950000 | Ù…ÙƒØªØ¨ Ø´Ø±ÙŠØ· Ù„Ù„Ø¹Ù‚Ø§Ø±Ø§Øª\n",
      "Ø¯ÙˆØ± | Ø´Ù…Ø§Ù„ | Ø§Ù„Ø¹Ù„ÙŠØ§ | 4 | 4 | 126 | 1560000 | Ø´Ø±ÙƒØ© Ù…Ø¨Ø§Ø´Ø± Ù„Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ù„Ù„ØªØ³ÙˆÙŠÙ‚ Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠ\n",
      "Ø¯ÙˆØ± | Ø´Ø±Ù‚ | Ø§Ù„Ø§Ø²Ø¯Ù‡Ø§Ø± | 3 | 3 | 126 | 1899000 | Ø´Ø±ÙƒØ© Ù…Ø³ÙƒÙ† Ø§Ù„ÙŠÙ† Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠØ©\n",
      "Ø´Ù‚Ø© | Ø´Ù…Ø§Ù„ | Ø§Ù„Ø¹Ø§Ø±Ø¶ | 3 | 2 | 127 | 1149000 | Ø´Ø±ÙƒØ© Ø±Ø§ÙƒØ² Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠØ©\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"Dataset/cleaned_dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the \"Property_ID\" column as it's an identifier not useful for modeling.\n",
    "df = df.drop(columns=[\"Property_ID\"], errors='ignore')\n",
    "\n",
    "# Define the numerical features which we will use for analysis and predictions.\n",
    "num_features = [\"Area\", \"Price\"]\n",
    "\n",
    "# These columns will keep the original, unscaled values to display later in the recommendations.\n",
    "df[\"Original_Area\"] = df[\"Area\"]\n",
    "df[\"Original_Price\"] = df[\"Price\"]\n",
    "\n",
    "# A preprocessing pipeline is created using a StandardScaler to normalize the 'Area' and 'Price' columns for consistent scaling of the data.\n",
    "preprocessor = Pipeline([\n",
    "    ('scaler', StandardScaler())  # This scales the features to have zero mean and unit variance.\n",
    "])\n",
    "\n",
    "# Normalize the numerical features (Area and Price).\n",
    "df[num_features] = preprocessor.fit_transform(df[num_features])\n",
    "\n",
    "# Generate similarity labels for training, This function assigns a 'Similarity_Label' to properties based on their proximity to each other in price and area.\n",
    "# If a property is similar to others, it gets a label of 1, otherwise, it stays 0.\n",
    "df[\"Similarity_Label\"] = 0  # Default label is \"Not similar\".\n",
    "\n",
    "def assign_similarity_labels(df, threshold=0.1):\n",
    "    for i, row in df.iterrows():\n",
    "        area, price = row[\"Area\"], row[\"Price\"]\n",
    "        # Calculate the Euclidean distance between this property and all others.\n",
    "        distances = np.sqrt((df[\"Area\"] - area) ** 2 + (df[\"Price\"] - price) ** 2)\n",
    "        closest_indices = distances.nsmallest(6).index  # Get the closest 5 properties plus itself.\n",
    "        df.loc[closest_indices, \"Similarity_Label\"] = 1  # Mark these properties as similar.\n",
    "\n",
    "assign_similarity_labels(df)\n",
    "\n",
    "# We will split the data into a training set (80%) and a testing set (20%) for model evaluation.\n",
    "X = df[num_features]\n",
    "y = df[\"Similarity_Label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# We will train several models, including KNN, Random Forest, and Gradient Boosting.\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100)\n",
    "}\n",
    "\n",
    "# Train each model and evaluate it using accuracy and classification report.\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Train the model on the training set.\n",
    "    y_pred = model.predict(X_test)  # Make predictions on the test set.\n",
    "    \n",
    "    # Output the accuracy score and classification report for each model.\n",
    "    print(f\"{name} Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"{name} Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# This function will return a list of recommended properties based on the price and area specified by the user.\n",
    "def recommend_properties(price, area, model_name, top_n=5):\n",
    "    # Create a DataFrame with the appropriate columns and pass it to the scaler\n",
    "    input_data = pd.DataFrame([[area, price]], columns=num_features)\n",
    "    \n",
    "    # Preprocess the input data (price and area) using the same scaler as the training data.\n",
    "    input_data = preprocessor.transform(input_data)\n",
    "    \n",
    "    # Get the model\n",
    "    model = models.get(model_name)\n",
    "    \n",
    "    # Calculate the similarity score for all properties in the dataset using the model's predictions.\n",
    "    probabilities = model.predict_proba(df[num_features])[:, 1]\n",
    "    df[\"Similarity_Score\"] = probabilities\n",
    "    \n",
    "    # Get the top 5 properties with the highest similarity score.\n",
    "    recommended = df.nlargest(top_n, \"Similarity_Score\").copy()\n",
    "    \n",
    "    # Rename the columns to display in Arabic for the output.\n",
    "    recommended = recommended.rename(columns={\n",
    "        \"Property Type\": \"Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø§Ø±\",\n",
    "        \"Location\": \"Ø§Ù„Ù…ÙˆÙ‚Ø¹\",\n",
    "        \"District\": \"Ø§Ù„Ø­ÙŠ\",\n",
    "        \"Bedrooms\": \"Ø§Ù„ØºØ±Ù\",\n",
    "        \"Bathrooms\": \"Ø¯ÙˆØ±Ø§Øª Ø§Ù„Ù…ÙŠØ§Ø©\",\n",
    "        \"Original_Area\": \"Ø§Ù„Ù…Ø³Ø§Ø­Ø©\",\n",
    "        \"Original_Price\": \"Ø§Ù„Ø³Ø¹Ø±\",\n",
    "        \"Agency_Name\": \"Ø§Ù„ÙˆÙƒØ§Ù„Ø©\"\n",
    "    })\n",
    "    \n",
    "    # Prepare the headers and results for displaying.\n",
    "    headers = [\"Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø§Ø±\", \"Ø§Ù„Ù…ÙˆÙ‚Ø¹\", \"Ø§Ù„Ø­ÙŠ\", \"Ø§Ù„ØºØ±Ù\", \"Ø¯ÙˆØ±Ø§Øª Ø§Ù„Ù…ÙŠØ§Ø©\", \"Ø§Ù„Ù…Ø³Ø§Ø­Ø©\", \"Ø§Ù„Ø³Ø¹Ø±\", \"Ø§Ù„ÙˆÙƒØ§Ù„Ø©\"]\n",
    "    results = recommended[headers]\n",
    "    \n",
    "    # Print the headers and the corresponding recommended properties in a clean format.\n",
    "    print(\"\\n\" + \" | \".join(headers))\n",
    "    print(\"-\" * 120)  \n",
    "    for index, row in results.iterrows():\n",
    "        print(\" | \".join(str(x) for x in row.values))\n",
    "    print(\"-\" * 120)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage of the recommendation function:\n",
    "price_input = 980000\n",
    "area_input = 300\n",
    "\n",
    "# Loop through all models and print recommendations for each one.\n",
    "for model_name in models.keys():\n",
    "    print(f\"\\nğŸ”¹ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© ÙˆØ§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ¯Ù„ {model_name}:\\n\")\n",
    "    recommend_properties(price_input, area_input, model_name=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dee54d-c68b-4c31-a9cf-2be854213bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b678b35-85e5-4abb-b6d7-9c7128a59ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
